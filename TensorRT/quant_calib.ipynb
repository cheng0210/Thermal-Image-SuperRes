{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import datetime\r\n",
    "import os\r\n",
    "import sys\r\n",
    "import time\r\n",
    "import collections\r\n",
    "import argparse\r\n",
    "import torch\r\n",
    "import torch.utils.data\r\n",
    "from torch import nn\r\n",
    "import h5py\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "import torchvision\r\n",
    "from torchvision import transforms\r\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\r\n",
    "from pytorch_quantization import nn as quant_nn\r\n",
    "from pytorch_quantization import calib\r\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\r\n",
    "from utils import customDataset\r\n",
    "from EDSR_Quant.model import EDSR\r\n",
    "from RRDBNet_Quant.model import RRDBNet\r\n",
    "from sklearn.model_selection import KFold\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "E0915 00:17:57.726973 140157013657408 amp_wrapper.py:31] AMP is not avaialble.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "quant_desc_input = QuantDescriptor(calib_method='histogram', axis=None)\r\n",
    "quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)\r\n",
    "quant_desc_weight = QuantDescriptor(calib_method='histogram', axis=None)\r\n",
    "quant_nn.QuantConv2d.set_default_quant_desc_weight(quant_desc_weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "parser = argparse.ArgumentParser(description=\"SuperRes Pytorch\")\r\n",
    "parser.add_argument(\"--model\", type=str, help=\"model name\")\r\n",
    "parser.add_argument(\"--ckpt\", type=str, help=\"checkpoint path\")\r\n",
    "parser.add_argument(\"--kfoldIndex\", default=0, type=int, help=\"start kfold valid index 0 ~ 9\")\r\n",
    "opt = parser.parse_args()\r\n",
    "if opt.model is None:\r\n",
    "        print(\"model name?\")\r\n",
    "elif not torch.cuda.is_available():\r\n",
    "    print(\"cuda is not available\")\r\n",
    "else:\r\n",
    "    print(\"===> Loading model\")\r\n",
    "    if opt.model == \"EDSR\":\r\n",
    "        model = EDSR(opt.scale, lr=opt.lr, batch_size=opt.batchSize)\r\n",
    "        print(\"Model EDSR is loaded\")\r\n",
    "    elif opt.model == \"RRDBNet\":\r\n",
    "        model = RRDBNet(64, 23, scale_factor=opt.scale, lr=opt.lr, batch_size=opt.batchSize)\r\n",
    "        print(\"Model RRDBNet is loaded\")\r\n",
    "\r\n",
    "model = model.load_from_checkpoint(opt.ckpt)\r\n",
    "model.cuda()\r\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RRDBNet(\n",
       "  (input_conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (rrdb): Sequential(\n",
       "    (0): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (6): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (7): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (8): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (9): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (10): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (11): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (12): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (13): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (14): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (15): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (16): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (17): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (18): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (19): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (20): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (21): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "    (22): ResidualInResidualDenseBlock(\n",
       "      (layer1): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer2): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "      (layer3): ResidualDenseBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        )\n",
       "        (layer5): Sequential(\n",
       "          (0): QuantConv2d(\n",
       "            192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "            (_input_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "            (_weight_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "          )\n",
       "        )\n",
       "        (residual_quantizer): TensorQuantizer(8bit narrow fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (rrdb_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upscale2x): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): PixelShuffle(upscale_factor=2)\n",
       "  )\n",
       "  (upscale3x): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): PixelShuffle(upscale_factor=3)\n",
       "  )\n",
       "  (upscale4x): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): PixelShuffle(upscale_factor=2)\n",
       "    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (3): PixelShuffle(upscale_factor=2)\n",
       "  )\n",
       "  (output_conv): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(\"===> Loading datasets\")\r\n",
    "\r\n",
    "# change dir here\r\n",
    "hf = h5py.File(\"/media/jacob/Elements/thermal-images-datasets/FLIR_ADAS_1_3/merged/output/FLIR16_x\"+str(4)+\".hdf5\", 'r')\r\n",
    "inputs = hf.get(\"input\")\r\n",
    "labels = hf.get(\"label\")\r\n",
    "\r\n",
    "kf = KFold(n_splits=10)\r\n",
    "kf_index = 0\r\n",
    "\r\n",
    "for trainFold_indexes, testFold_indexes in kf.split(inputs):\r\n",
    "    if kf_index < opt.kfoldIndex:\r\n",
    "        kf_index+=1\r\n",
    "        continue\r\n",
    "    print(\"===> Start K-FOLD Index \" + str(kf_index))\r\n",
    "\r\n",
    "    train_dataset = customDataset(inputs[trainFold_indexes], labels[trainFold_indexes])\r\n",
    "    test_dataset = customDataset(inputs[testFold_indexes], labels[testFold_indexes])\r\n",
    "\r\n",
    "    training_dataloader = DataLoader(dataset=train_dataset, num_workers=8, batch_size=16, shuffle=True)\r\n",
    "    testing_dataloader = DataLoader(dataset=test_dataset, num_workers=8, batch_size=16)\r\n",
    "\r\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===> Loading datasets\n",
      "===> Start K-FOLD Index 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\r\n",
    "\r\n",
    "def collect_stats(model, data_loader, num_batches):\r\n",
    "    \"\"\"Feed data to the network and collect statistic\"\"\"\r\n",
    "\r\n",
    "    # Enable calibrators\r\n",
    "    for name, module in model.named_modules():\r\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\r\n",
    "            if module._calibrator is not None:\r\n",
    "                module.disable_quant()\r\n",
    "                module.enable_calib()\r\n",
    "            else:\r\n",
    "                module.disable()\r\n",
    "\r\n",
    "    for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\r\n",
    "        model(image.cuda())\r\n",
    "        if i >= num_batches:\r\n",
    "            break\r\n",
    "\r\n",
    "    # Disable calibrators\r\n",
    "    for name, module in model.named_modules():\r\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\r\n",
    "            if module._calibrator is not None:\r\n",
    "                module.enable_quant()\r\n",
    "                module.disable_calib()\r\n",
    "            else:\r\n",
    "                module.enable()\r\n",
    "            \r\n",
    "def compute_amax(model, **kwargs):\r\n",
    "    # Load calib result\r\n",
    "    for name, module in model.named_modules():\r\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\r\n",
    "            if module._calibrator is not None:\r\n",
    "                if isinstance(module._calibrator, calib.MaxCalibrator):\r\n",
    "                    module.load_calib_amax()\r\n",
    "                else:\r\n",
    "                    module.load_calib_amax(**kwargs)\r\n",
    "            #print(F\"{name:40}: {module}\")\r\n",
    "    model.cuda()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#test multiple calib methods and pick the best one to save\r\n",
    "with torch.no_grad():\r\n",
    "    collect_stats(model, training_dataloader, num_batches=64)\r\n",
    "    compute_amax(model, method=\"percentile\", percentile=99.9999)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 64/64 [3:10:45<00:00, 178.83s/it]\n",
      "W0915 03:28:54.717801 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.718474 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.718885 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.719257 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.719624 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.719974 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.720334 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.721221 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.721603 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.721968 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.722348 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.722774 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.723247 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.723614 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.724063 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.724421 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.724870 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.725223 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.725719 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.726103 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.728325 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.728726 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.729107 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.729508 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.729890 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.730317 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.730737 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.731089 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.731371 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.731629 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.731867 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.732102 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.732319 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.733101 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.733370 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.733687 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.734021 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.734849 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.735085 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.735294 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.735515 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.735747 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.735971 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.736188 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.736400 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.736600 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.736815 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.737032 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.737249 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.737441 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.737680 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.737889 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.738096 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.738307 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.738520 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.738721 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.738919 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.739120 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.739340 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.739545 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.739742 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.739941 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.740148 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.740371 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.740569 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.740765 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.740976 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.741183 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.741393 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.741595 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.743337 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.743544 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.743727 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.743899 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.744103 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.744302 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.744479 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.744659 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.744832 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.745009 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.745186 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.745371 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.745545 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.745739 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.745912 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.746094 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.746278 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.746454 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.746630 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.746807 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.746984 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.747160 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.747348 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.747523 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.747700 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.747876 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.748050 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.748222 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.748401 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.748579 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.748757 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.748936 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.749106 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.749294 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.749469 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.749664 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.749842 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.750024 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.750228 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.752406 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.752613 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.752801 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.752987 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.753168 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.753361 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.753537 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.753725 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.753901 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.754086 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.754267 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.754447 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.754626 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.754802 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.754992 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.755166 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.755357 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.755534 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.755709 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.755903 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.756080 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.756253 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.756438 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.756619 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.756797 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.756976 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.757157 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.757348 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.757525 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.757714 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.757890 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.758074 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.758248 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.758436 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.758622 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.758971 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.759149 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.759326 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.759513 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.759688 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.759863 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.760037 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.760215 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.760403 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.760576 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.760753 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.760926 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.761104 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.761284 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.761471 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.761663 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.761867 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.762063 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.762275 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.762499 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.762687 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.762901 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.766183 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.766388 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.766591 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.766799 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.767022 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.767240 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.767460 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.767668 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.767879 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.768074 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.768284 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.768521 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.769403 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.769649 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.769857 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.770087 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.770585 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.770779 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.770969 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.771146 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.771329 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.771523 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.771698 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.771880 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.772059 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.772257 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.772435 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.772619 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.772790 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.772967 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.773143 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.773316 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.773539 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.773777 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.775129 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.775421 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.775717 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.775971 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.776239 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.776492 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.776742 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.776940 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.777150 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.777401 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.777680 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.778553 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.778846 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.779081 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.779309 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.779622 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.779889 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.780209 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.781048 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.781319 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.781826 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.782108 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.782388 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.782688 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.783092 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.783484 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.783842 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.784155 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.784474 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.784741 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.784984 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.785227 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.785497 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.785776 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.786101 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.786388 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.786661 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.786930 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.787166 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.787396 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.787618 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.787854 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.788087 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.788321 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.788595 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.788836 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.789086 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.789342 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.789582 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.789831 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.790049 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.790272 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.790490 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.790725 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.790940 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.791156 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.791380 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.791613 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.791826 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.792045 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.792302 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.792538 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.792754 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.793073 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.793386 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.793691 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.794006 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.794365 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.794673 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.794970 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.795259 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.795545 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.795826 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.796079 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.796295 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.796511 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.796764 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.797119 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.797367 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.797597 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.797827 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.798032 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.798234 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.798504 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.798738 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.799852 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.800050 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.800236 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.800486 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.800690 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.800919 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.801145 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.801339 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.801546 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.801771 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.802025 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.802240 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.802510 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.805676 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.805904 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.806104 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.806317 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.806514 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.806695 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.806864 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.807034 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.807201 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.807782 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.807965 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.808146 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.808515 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.808699 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.808883 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.809043 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.809216 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.809381 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.809556 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.809750 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.809918 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.810097 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.810263 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.810433 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.810595 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.810761 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.810947 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.811125 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.811289 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.811456 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.811620 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.812654 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.812832 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.813003 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.813195 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.813371 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.813552 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.813743 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.813914 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.814082 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.814266 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.814449 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.814622 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.814808 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.814989 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.815177 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.815385 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.815578 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.815775 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.816866 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.817120 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.817326 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.817535 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.817900 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.818094 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.818275 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.818464 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.818666 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.818863 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.819044 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.819234 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.819444 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.819633 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.819841 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.820053 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.820255 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.820440 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.820637 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.820821 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.821019 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.821215 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.821412 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.821610 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.821811 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.821999 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.822184 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.822380 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.822565 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.822797 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.822982 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.823173 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.823353 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.823552 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.823748 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.823967 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.824158 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.824354 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.824550 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.824755 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.824966 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.825176 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.825392 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.825617 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.825843 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.826058 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.826269 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.826483 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.826688 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.826904 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.827120 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.827339 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.827539 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.827744 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.827945 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.828165 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.828390 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.828635 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.828855 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.829081 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.829295 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.829497 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.829726 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.829972 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.830192 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.830392 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.830596 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.830806 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.831034 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.834906 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.835154 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.835345 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.835529 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.835722 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.835906 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.836092 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.836277 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.836478 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.836671 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.836864 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.837049 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.837236 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.837425 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.837618 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.837814 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.838010 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.838204 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.838390 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.838578 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.838759 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.838948 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.839134 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.839320 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.839513 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.839695 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.839890 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.840074 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.840263 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.840451 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.840637 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.840822 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.841011 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.841197 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.841383 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.841571 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.841765 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.841952 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.842139 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.842332 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.844309 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.844510 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.844689 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.844876 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.845057 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.845248 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.845444 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.845636 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.845831 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.846019 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.846209 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.846393 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.846580 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.846764 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.846954 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.847135 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.847317 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.847513 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.847701 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.848754 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.848939 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.849126 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.849317 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.849506 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.849716 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.849918 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.850102 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.850297 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.850489 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.850674 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.850863 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.851051 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.851247 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.851435 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.851625 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.851844 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.852036 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.852244 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.852446 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.852642 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.852828 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.853029 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.853217 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.853408 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.853606 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.853809 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.853994 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.854191 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.854376 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.854563 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.854760 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.854951 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.855148 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.855340 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.855536 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.855727 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.855918 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.856112 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.856302 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.856492 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.856678 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.856878 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.857069 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.857261 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.857453 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.857657 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.857847 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.858041 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.858234 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.858429 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.858618 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.858808 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.859007 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.859203 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.859390 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.859583 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.859799 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.861861 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.863526 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.863748 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.863972 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.864226 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.864887 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.865112 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.865352 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.865563 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.865807 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.866044 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.866275 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.866507 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.866727 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.866956 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.867860 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.868103 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.868342 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.868805 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.869220 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.869422 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.869629 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.870010 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.870208 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.870394 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.870589 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.870788 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.870978 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.871175 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.871364 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.871563 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.871752 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.871944 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.872133 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.872346 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.872538 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.872733 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.872923 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.873895 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.874090 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.874282 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.874474 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.874659 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.874856 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.875047 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.875233 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.875419 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.875615 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.875805 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.875988 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.876177 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.876362 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.876551 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.877476 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.877684 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.877905 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.878255 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.878457 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.878690 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.878896 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.879111 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.879314 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.879545 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.879746 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.879928 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.880117 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.880297 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.880483 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.880665 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.880848 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.881030 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.881208 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.881396 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.881575 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.881769 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.881993 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.882181 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.882378 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.882570 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.882774 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.882982 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.883178 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.883366 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.883577 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.883780 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.883976 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.884164 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.884364 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.884557 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.884756 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.886565 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.886774 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.886968 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.887162 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.887362 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.887550 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.887741 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.887924 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.888114 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.888306 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.888496 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.888679 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.888866 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.889049 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.889239 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.889427 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.889620 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.889816 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.890003 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.890196 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.890386 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.890583 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.890774 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.890974 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.891157 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.891337 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.891521 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.891700 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.891881 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.892063 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.892254 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.892469 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.892701 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.894477 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.894691 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.894887 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.895076 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.895287 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.895471 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.895658 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.895837 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.896022 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.896219 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.896399 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.896585 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.896782 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.896969 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.897158 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.897351 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.897552 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.898537 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.898720 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.898901 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.899100 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.899299 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.899509 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.899720 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.899923 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.900118 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.900791 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.901018 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.901241 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.901444 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.901667 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.901891 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.902182 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.902422 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.902650 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.902869 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.903092 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.903307 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.903511 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.903721 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.903936 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.904141 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.904343 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.904550 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.904752 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.904958 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.905160 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.905361 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.905583 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.905808 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.906012 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.906212 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.906428 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.906631 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.906839 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.907045 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.907263 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.907472 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.907667 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.907867 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.908087 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.908286 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.908483 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.908694 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.911052 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.911278 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.911515 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.911732 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.911974 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.912181 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.912429 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.912677 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.913351 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.913572 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.913781 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.913967 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.914165 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.914357 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.914546 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.914727 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.914902 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.915096 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.915284 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.915468 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.915648 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.915836 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.916040 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.916228 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.916411 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.916608 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.917664 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.917863 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.918427 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.918720 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.918941 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.919137 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.919328 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.919519 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.919714 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.920332 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.920531 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.920717 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.920897 140157013657408 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0915 03:28:54.921822 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.922034 140157013657408 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0915 03:28:54.922439 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.922784 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.923114 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.923452 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.923771 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.924104 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.924433 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.924766 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.925160 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.925562 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.925922 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.926247 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.926573 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.926887 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.927207 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.927514 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.927825 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.928207 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.928537 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.928849 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.929161 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.929480 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.929816 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.930138 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.930443 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.930787 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.931260 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.931706 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.932336 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.932817 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.933277 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.933648 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.934215 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.934623 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.935115 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.935535 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.935981 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.936441 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.936875 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.937320 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.937788 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.938193 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.938634 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.939084 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.939489 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.939965 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.940383 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.940798 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.941212 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.941620 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.942006 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.942397 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.942771 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.943154 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.943559 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.943950 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.944355 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.944997 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.945419 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.945841 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.946254 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.946658 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.947135 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.947538 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.947934 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.948350 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.948745 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.949157 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.949564 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.950021 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.950412 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.950887 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.951325 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.951837 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.952361 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.952893 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.953310 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.953942 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.954370 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.954780 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.955197 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.955592 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.955991 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.956393 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.956806 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.957204 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.957611 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.958032 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.958438 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.958854 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.959260 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.959821 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.960212 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.960634 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.961079 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.961497 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.961911 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.962323 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.962736 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.963207 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.963625 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.964027 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.964420 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.964819 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.965218 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.965617 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.966034 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.966446 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.966845 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.967277 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.967671 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.968077 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.968481 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.968894 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.969280 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.969693 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.970098 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.970503 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.970886 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.971453 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.971866 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.972258 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.972817 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.973221 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.973639 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.974042 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.974435 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.974817 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.975218 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.975770 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.976169 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.976607 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.977167 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.977682 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.978151 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.978572 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.978978 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.979430 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.979917 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.980374 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.980770 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.981241 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.981668 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.982087 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.982502 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.982977 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.983470 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.983894 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.984301 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.984696 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.985097 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.985498 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.986041 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.986447 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.986854 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.987267 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.987658 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.988064 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.988460 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.988885 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.989350 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.989788 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.990226 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.990611 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.991022 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.991413 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.991808 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.992203 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.992607 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.993132 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.993522 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.993920 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.994319 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.994722 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.995114 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.995516 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.995892 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.996312 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.996701 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.997090 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.997466 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.997874 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.998280 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.998814 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.999199 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:54.999580 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.000005 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.000399 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.000803 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.001193 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.001596 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.001985 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.002400 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.002780 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.003165 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.003531 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.003911 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.004293 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.004671 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.005055 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.005428 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.005834 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.006226 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.006619 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.007011 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.007562 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.007977 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.008372 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.008776 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.009185 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.009589 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.009986 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.010399 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.010796 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.011196 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.011606 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.012158 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.012552 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.012956 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.013366 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.013760 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.014160 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.014543 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.015096 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.015500 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.015922 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.016321 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.016768 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.017163 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.017573 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.017989 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.018538 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.019112 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.019669 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.020083 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.020473 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.020879 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.021285 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.021692 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.022087 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.022473 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.023017 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.023554 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.023962 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.024351 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.024933 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.025320 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.025762 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.026171 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.026581 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.026980 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.027395 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.027903 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.028249 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.028817 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.029158 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.029757 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.030278 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.030802 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.031489 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.031980 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.032451 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.032931 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.033436 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.033918 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.034401 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.034861 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.035314 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.035770 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.036222 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.036679 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.037132 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.037584 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.038037 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.038491 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.038938 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.039384 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.039836 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.040284 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.040664 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.041030 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.041367 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.041748 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.042252 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.042609 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.042992 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.043321 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.043665 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.043996 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.044334 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.044686 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.045038 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.045383 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.045730 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.046192 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.046538 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.046895 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.047248 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.047603 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.047967 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.048318 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.048687 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.049026 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.049368 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.049726 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.050060 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.050400 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.050743 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.051085 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.051433 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.051772 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.052119 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.052452 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.052804 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.053154 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.053486 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.053936 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.054274 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.054679 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.055044 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.055413 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.055782 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.056150 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.056515 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.056886 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.057157 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.057559 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.058120 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.058505 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.058801 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.059109 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.059686 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.060036 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.060304 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.060612 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.060911 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.061213 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.061529 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.062492 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.062856 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.063221 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.063594 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.063965 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.064330 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.064697 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.065061 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.065435 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.065819 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.066098 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.066478 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.066781 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.067094 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.067385 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.067684 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.067978 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.068282 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.068575 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.068872 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.069164 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.069470 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.069782 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.070073 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.070383 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.070682 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.070986 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.071277 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.071581 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.071879 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.072180 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.072479 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.072780 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.073071 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.073361 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.073656 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.073945 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.074250 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.074537 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.074834 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.075128 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.075428 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.075717 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.076019 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.076314 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.076602 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.076900 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.077185 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.077477 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.077773 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.078072 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.078360 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.078661 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.078949 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.079251 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.079539 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.079828 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.080132 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.080429 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.080723 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.081020 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.081317 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.081617 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.081914 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.082207 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.082508 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.082799 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.083092 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.083402 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.083705 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.084017 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.084319 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.084616 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.084918 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.085208 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.085490 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.085788 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.086073 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.086359 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.086648 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.086942 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.087235 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.087532 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.087827 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.088125 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.088500 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.088861 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.089229 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.089596 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.089959 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.090336 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.090706 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.090974 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.091397 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.091871 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.092238 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.092603 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.092964 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.093319 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.093694 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.094050 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.094408 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.094674 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.095329 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.095624 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.095925 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.096525 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.096915 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.097209 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.097765 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.098124 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.098488 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.098862 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.099232 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.099599 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.099863 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.100428 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.100780 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.101027 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.101842 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.102393 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.102757 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.103119 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.103478 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.103795 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.104284 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.104622 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.104973 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.105314 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.105672 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.106023 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.106374 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.106710 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.107053 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.107399 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.107746 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.108098 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.108442 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.108785 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.109123 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.109461 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.109802 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.110144 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.110473 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.110813 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.111206 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.111556 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.111905 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.112236 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.112589 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.112920 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.113263 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.113603 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.113960 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.114305 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.114643 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.114998 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.115330 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.115778 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.116089 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.116397 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.116715 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.117015 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.117306 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.117615 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.117917 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.118214 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.118510 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.118808 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.119117 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.119409 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.119720 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.120019 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.120312 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.120605 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.120911 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.121203 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.121492 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.121798 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.122093 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.122392 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.122685 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.122984 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.123279 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.123576 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.123865 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.124166 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.124458 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.124748 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.125044 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.125334 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.125638 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.125932 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.126230 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.126525 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.126830 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.127121 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.127421 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.127711 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.128006 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.128320 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.128613 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.128908 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.129200 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.129495 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.129799 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.130100 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.130431 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.130774 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.131081 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.131377 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.131676 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.131967 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.132261 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.132558 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.132887 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.133217 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.133550 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.133889 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.134217 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.134544 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.134884 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.135221 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.135552 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.135893 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.136231 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.136564 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.136895 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.137254 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.137590 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.137931 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.138252 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.138582 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.138915 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.139245 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.139571 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.139897 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.140233 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.140564 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.140890 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.141221 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.141556 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.141856 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.142148 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.142440 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.142735 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.143045 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.143354 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.143663 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.143970 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.144281 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.144595 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.144942 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.145306 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.145636 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.145974 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.146287 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.146610 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.146928 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.147242 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.147555 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.147872 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.148184 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.148505 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.148829 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.149139 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.149580 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.150108 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.150478 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.150833 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.151198 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.151561 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.151908 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.152260 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.152621 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.152967 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.153318 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.153686 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.154033 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.154389 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.154741 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.155098 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.155451 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.155804 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.156154 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.156501 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.156847 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.157218 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.157581 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.157946 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.158300 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.158655 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.159016 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.159357 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.159716 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.160064 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.160417 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.160758 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.161103 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.161522 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.161894 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.162257 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.162610 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.162966 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.163306 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.163658 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.164008 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.164358 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.164707 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.165055 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.165409 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.165848 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.166207 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.166547 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.166898 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.167243 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.167598 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.167948 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.168304 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.168652 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.168991 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.169347 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.169701 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.170051 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.170400 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.170756 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.171105 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.171456 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.171802 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.172152 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.172502 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.172847 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.173200 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.173550 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.173946 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.174345 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.174709 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.175034 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.175362 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.175683 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.176007 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.176331 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.176645 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.176972 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.177285 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.177609 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.177939 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.178264 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.178576 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.178891 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.179217 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.179531 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.179845 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.180166 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.180494 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.180809 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.181128 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.181443 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.181757 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.182073 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.182468 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.182810 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.183173 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.183527 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.183875 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.184237 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.184594 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.184948 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.185312 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.185679 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.186024 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.186395 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.186753 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.187114 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.187481 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.187832 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.188211 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.188568 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.188927 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.189282 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.189652 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.190008 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.190376 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.190724 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.191075 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.191431 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.191783 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.192147 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.192528 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.192894 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.193246 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.193527 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.194141 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.194618 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.194950 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.195538 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.195925 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.196312 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.196702 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.197066 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.197444 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.197822 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.198197 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.198567 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.198929 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.199292 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.199657 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.200023 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.200388 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.200754 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.201125 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.201499 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.201879 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.202253 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.202612 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.202979 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.203342 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.203708 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.204066 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 03:28:55.204424 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pytorch_lightning as pl\r\n",
    "trainer = pl.Trainer(gpus=1)\r\n",
    "trainer.validate(model, dataloaders=testing_dataloader)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "I0915 03:28:59.732511 140157013657408 distributed.py:90] GPU available: True, used: True\n",
      "I0915 03:28:59.733161 140157013657408 distributed.py:90] TPU available: False, using: 0 TPU cores\n",
      "I0915 03:28:59.733516 140157013657408 distributed.py:90] IPU available: False, using: 0 IPUs\n",
      "I0915 03:28:59.734261 140157013657408 gpu.py:54] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/jacob/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:373: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  f\"Your {mode}_dataloader has `shuffle=True`, it is best practice to turn\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validating: 100%|██████████| 256/256 [02:15<00:00,  1.90it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'psnr': 46.499271392822266,\n",
      " 'val_L1loss': 66.49312591552734,\n",
      " 'val_L2loss': 7671.87890625}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'psnr': 46.499271392822266,\n",
       "  'val_L1loss': 66.49312591552734,\n",
       "  'val_L2loss': 7671.87890625}]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "with torch.no_grad():\r\n",
    "    compute_amax(model, method=\"percentile\", percentile=99.99)\r\n",
    "    trainer.validate(model, dataloaders=testing_dataloader)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "W0915 15:30:49.167002 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.167884 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.168576 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.169400 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.170192 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.170967 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.171812 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.172519 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.173265 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.173903 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.174679 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.175223 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.175825 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.176438 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.176912 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.177482 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.178131 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.178744 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.179127 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.179547 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.179878 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.180486 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.180981 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.181345 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.181733 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.182104 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.182523 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.182997 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.183363 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.183744 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.184130 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.184474 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.184843 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.185178 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.185500 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.185863 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.186230 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.186579 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.186912 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.187275 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.187545 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.187945 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.188311 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.188652 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.189014 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.189392 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.189789 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.190159 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.190500 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.190835 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.191260 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.191598 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.191941 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.192268 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.192590 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.192960 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.193321 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.193700 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.194059 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.194420 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.194786 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.195146 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.195495 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.195862 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.196205 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.196559 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.196921 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.197289 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.197660 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.198006 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.198369 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.198754 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.199326 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.199931 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.200536 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.200994 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.201452 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.201891 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.202261 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.202616 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.202876 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.203308 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.203648 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.203990 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.204321 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.204665 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.204990 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.205324 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.205668 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.205995 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.206320 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.206634 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.206972 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.207557 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.208031 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.208386 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.208734 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.209071 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.209410 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.209778 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.210219 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.210801 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.211238 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.212018 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.212649 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.213098 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.213535 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.213979 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.214375 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.214747 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.215127 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.215472 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.215788 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.216083 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.216378 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.216668 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.217041 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.217472 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.217839 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.218163 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.218480 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.218792 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.219187 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.219635 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.220005 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.220373 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.220716 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.221052 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.221370 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.221709 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.222028 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.222345 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.222672 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.223021 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.223379 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.223730 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.224083 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.224426 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.224776 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.225148 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.225521 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.225882 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.226229 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.226576 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.226939 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.227446 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.227797 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.228288 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.228641 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.229003 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.229349 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.229788 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.230148 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.230485 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.230832 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.231168 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.231509 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.231847 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.232199 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.232538 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.232882 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.233217 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.233554 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.233904 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.234342 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.234867 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.235346 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.235746 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.236118 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.236631 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.237404 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.237867 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.238285 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.238699 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.239311 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.239653 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.240044 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.240431 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.240705 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.241126 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.241514 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.241901 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.242226 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.242480 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.242959 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.243336 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.243707 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.244192 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.244611 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.244988 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.245356 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.245860 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.246374 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.246870 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.247360 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.247771 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.248108 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.248435 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.248766 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.249084 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.249408 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.249729 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.250067 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.250384 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.250707 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.251021 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.251339 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.251652 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.251963 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.252275 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.252581 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.252896 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.253207 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.253525 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.253844 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.254162 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.254470 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.254792 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.255101 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.255413 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.255729 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.256032 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.256343 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.256649 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.256961 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.257266 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.257593 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.257916 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.258231 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.258534 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.258863 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.259206 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.259540 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.259882 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.260218 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.260559 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.260891 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.261231 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.261563 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.261916 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.262248 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.262588 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.262934 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.263265 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.263608 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.263940 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.264286 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.264621 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.264963 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.265305 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.265662 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.266003 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.266340 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.266684 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.267020 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.267362 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.267697 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.268035 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.268374 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.268719 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.269080 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.269424 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.269771 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.270115 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.270458 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.270795 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.271157 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.271492 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.271835 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.272168 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.272511 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.272842 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.273203 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.273539 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.273887 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.274247 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.274582 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.274938 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.275337 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.275723 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.276082 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.276493 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.276900 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.277335 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.277717 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.278076 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.278432 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.278780 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.279131 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.279492 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.279843 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.280187 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.280563 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.280911 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.281275 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.281646 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.281999 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.282358 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.282720 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.283073 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.283418 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.283794 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.284137 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.284489 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.284849 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.285197 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.285537 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.286017 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.286444 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.286814 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.287183 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.287858 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.288229 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.288586 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.288942 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.289289 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.289651 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.289999 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.290482 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.290866 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.291219 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.291572 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.291936 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.292585 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.293028 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.293437 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.293897 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.294307 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.294697 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.295090 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.295510 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.295913 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.296391 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.296921 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.297490 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.298030 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.298540 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.299035 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.299559 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.300068 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.300569 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.301082 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.301600 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.302123 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.302625 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.303102 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.303571 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.304023 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.304445 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.304880 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.305327 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.305772 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.306210 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.306562 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.306910 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.307250 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.307642 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.307996 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.308348 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.308682 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.309017 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.309346 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.309705 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.310070 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.310405 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.310771 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.311106 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.311446 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.311785 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.312165 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.312493 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.312833 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.313154 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.313477 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.313817 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.314138 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.314464 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.314782 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.315121 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.315436 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.315760 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.316074 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.316396 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.316712 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.317032 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.317371 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.317701 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.318027 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.318343 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.318665 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.318982 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.319306 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.319620 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.319944 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.320255 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.320567 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.321009 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.321384 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.321761 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.322120 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.322480 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.322844 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.323204 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.323550 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.323910 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.324258 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.324608 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.324988 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.325376 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.325769 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.326131 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.326490 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.326861 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.327220 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.327588 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.327951 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.328295 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.328647 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.329004 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.329350 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.329720 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.330073 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.330427 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.330781 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.331139 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.331562 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.331970 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.332343 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.332711 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.333079 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.333441 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.333817 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.334177 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.334539 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.334895 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.335262 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.335623 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.335988 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.336338 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.336684 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.337041 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.337393 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.337800 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.338198 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.338573 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.338949 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.339331 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.339705 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.340126 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.340495 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.340873 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.341239 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.341617 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.342043 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.342471 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.343019 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.343538 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.344015 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.344433 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.344825 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.345190 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.345551 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.345956 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.346317 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.346688 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.346998 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.347312 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.347764 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.348138 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.348468 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.348781 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.349075 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.349369 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.349674 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.350018 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.350437 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.350794 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.351205 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.351583 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.351969 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.352309 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.352652 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.352996 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.353323 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.353667 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.354014 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.354349 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.354699 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.355088 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.355447 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.355851 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.356217 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.356543 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.357030 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.357539 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.357978 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.358369 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.358797 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.359215 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.359616 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.360136 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.360532 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.361047 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.361443 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.361829 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.362206 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.362605 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.362985 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.363368 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.363748 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.364140 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.364556 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.365011 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.365394 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.365823 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.366212 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.366592 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.367083 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.367605 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.368201 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.368820 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.369352 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.369797 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.370256 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.370700 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.371121 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.371536 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.372019 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.372524 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.372978 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.373428 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.374053 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.374501 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.374958 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.375367 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.375847 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.376305 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.376780 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.377199 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.377674 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.378183 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.378692 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.379115 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.379578 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.380087 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.380776 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.381252 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.381736 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.382080 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.382684 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.383112 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.383525 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.383946 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.384255 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.384748 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.385181 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.385598 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.386017 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.386460 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.386878 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.387305 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.387723 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.388164 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.388594 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.388997 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.389408 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.389813 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.390255 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.390679 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.391095 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.391507 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.391837 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.392280 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.392686 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.393109 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.393512 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.393954 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.394381 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.394889 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.395366 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.395828 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.396245 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.396644 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.397054 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.397460 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.397861 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.398246 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.398672 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.399052 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.399463 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.399798 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.400291 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.400695 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.401072 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.401648 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.402059 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.402460 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.402925 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.403352 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.403754 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.404156 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.404523 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.404928 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.405294 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.405689 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.406081 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.406457 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.406779 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.407311 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.407683 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.408338 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.408738 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.409131 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.409513 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.409903 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.410272 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.410653 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.411113 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.411558 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.412002 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.412393 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.412757 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.413129 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.413492 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.413880 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.414235 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.414586 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.414962 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.415314 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.415667 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.416032 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.416386 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.416747 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.417141 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.417498 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.417890 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.418247 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.418612 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.418992 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.419351 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.419704 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.420068 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.420421 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.420781 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.421145 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.421501 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.421889 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.422258 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.422664 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.423255 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.423639 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.424337 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.424720 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.425102 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.425449 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.425817 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.426171 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.426536 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.426883 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.427434 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.427822 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.428174 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.428520 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.428857 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.429196 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.429526 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.429932 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.430474 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.431005 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.431346 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.431677 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.432002 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.432326 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.432658 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.432967 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.433289 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.433611 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.433931 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.434246 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.434571 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.434880 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.435199 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.435528 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.435871 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.436230 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.436588 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.436992 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.437453 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.437945 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.438549 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.439021 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.439462 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.439913 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.440649 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.441418 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.441985 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.442461 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.442972 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.443611 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.444051 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.444468 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.444957 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.445407 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.445880 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.446310 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.446710 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.447126 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.447480 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.447926 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.448313 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.448708 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.449112 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.449483 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.449804 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.450266 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.450645 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.451087 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.451470 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.451908 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.452295 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.452668 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.453098 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.453454 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.453904 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.454288 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.454657 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.455039 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.455358 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.455699 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.456050 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.456377 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.456708 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.457063 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.457390 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.457744 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.458087 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.458405 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.458763 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.459100 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.459423 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.459775 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.460128 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.460524 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.460989 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.461408 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.461794 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.462268 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.462754 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.463138 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.463700 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.464190 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.464564 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.464972 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.465561 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.466033 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.466492 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.466946 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.467382 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0915 15:30:49.467998 140157013657408 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "I0915 15:30:49.506042 140157013657408 gpu.py:54] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validating: 100%|██████████| 256/256 [02:04<00:00,  2.17it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'psnr': 50.1746826171875,\n",
      " 'val_L1loss': 40.08448791503906,\n",
      " 'val_L2loss': 3097.244873046875}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "trainer.save_checkpoint(opt.model+\"_Quant.ckpt\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}